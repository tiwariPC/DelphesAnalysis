#!/usr/bin/env python3
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))
"""
Calculate sensitivity (significance, S/B) from datacards.

This script parses datacards generated by process_regions.py and calculates
sensitivity metrics for each region.
"""

import argparse
import re
from pathlib import Path
import numpy as np


def parse_datacard(datacard_file):
    """
    Parse datacard and extract yields and uncertainties.

    Parameters:
    -----------
    datacard_file : Path
        Path to datacard.txt file

    Returns:
    --------
    info : dict
        Dictionary with yields, processes, uncertainties
    """
    with open(datacard_file, 'r') as f:
        content = f.read()

    info = {
        "processes": [],
        "yields": {},
        "uncertainties": {},
        "bin_name": None,
        "observation": None
    }

    # Extract bin name
    bin_match = re.search(r'^bin\s+(\S+)', content, re.MULTILINE)
    if bin_match:
        info["bin_name"] = bin_match.group(1)

    # Extract observation
    obs_match = re.search(r'^observation\s+(-?\d+)', content, re.MULTILINE)
    if obs_match:
        info["observation"] = int(obs_match.group(1))

    # Extract process names
    proc_match = re.search(r'^process\s+(.+)', content, re.MULTILINE)
    if proc_match:
        processes = proc_match.group(1).split()
        info["processes"] = processes

    # Extract rates
    rate_match = re.search(r'^rate\s+(.+)', content, re.MULTILINE)
    if rate_match:
        rates = [float(x) for x in rate_match.group(1).split()]
        for proc, rate in zip(info["processes"], rates):
            info["yields"][proc] = rate

    # Extract uncertainties
    # Format: uncertainty_name type value1 value2 ...
    unc_pattern = r'^(\w+)\s+(\w+)\s+(.+)'
    for match in re.finditer(unc_pattern, content, re.MULTILINE):
        unc_name = match.group(1)
        unc_type = match.group(2)
        unc_values = [float(x) for x in match.group(3).split()]

        info["uncertainties"][unc_name] = {
            "type": unc_type,
            "values": unc_values
        }

    return info


def calculate_significance(signal, background):
    """
    Calculate expected significance.

    Parameters:
    -----------
    signal : float
        Signal yield
    background : float
        Total background yield

    Returns:
    --------
    z : float
        Expected significance
    """
    if background <= 0:
        return 0.0

    # Simple approximation for large B
    z_simple = signal / np.sqrt(background)

    # Asimov formula (more accurate)
    if signal > 0:
        z_asimov = np.sqrt(2 * ((signal + background) * np.log(1 + signal/background) - signal))
    else:
        z_asimov = 0.0

    return z_asimov


def calculate_sensitivity_for_region(datacard_file):
    """
    Calculate sensitivity metrics for a region.

    Parameters:
    -----------
    datacard_file : Path
        Path to datacard.txt file

    Returns:
    --------
    metrics : dict
        Dictionary with sensitivity metrics
    """
    info = parse_datacard(datacard_file)

    signal = info["yields"].get("signal", 0.0)
    backgrounds = {k: v for k, v in info["yields"].items() if k != "signal"}
    total_bg = sum(backgrounds.values())

    metrics = {
        "signal": signal,
        "total_background": total_bg,
        "backgrounds": backgrounds,
        "s_over_b": signal / total_bg if total_bg > 0 else 0.0,
        "significance": calculate_significance(signal, total_bg),
        "processes": info["processes"],
        "uncertainties": info["uncertainties"]
    }

    return metrics


def find_all_datacards(output_dir):
    """Find all datacard.txt files."""
    output_dir = Path(output_dir)
    plots_dir = output_dir / "plots"

    if not plots_dir.exists():
        return []

    datacards = []
    for region_dir in plots_dir.iterdir():
        if region_dir.is_dir():
            datacard_file = region_dir / "datacard.txt"
            if datacard_file.exists():
                datacards.append((datacard_file, region_dir.name))

    return datacards


def main():
    parser = argparse.ArgumentParser(
        description="Calculate sensitivity from datacards"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="output",
        help="Output directory from process_regions.py"
    )
    parser.add_argument(
        "--region",
        type=str,
        default=None,
        help="Calculate for specific region only"
    )
    parser.add_argument(
        "--format",
        type=str,
        default="table",
        choices=["table", "csv", "json"],
        help="Output format"
    )

    args = parser.parse_args()

    output_dir = Path(args.output_dir)

    # Find all datacards
    print("="*70)
    print("Finding Datacards")
    print("="*70)
    datacards = find_all_datacards(output_dir)

    if not datacards:
        print("✗ No datacards found!")
        return

    print(f"  Found {len(datacards)} datacards")

    # Filter by region if specified
    if args.region:
        datacards = [(dc, rn) for dc, rn in datacards if rn == args.region]
        if not datacards:
            print(f"✗ Region '{args.region}' not found!")
            return

    # Calculate sensitivity for each region
    print("\n" + "="*70)
    print("Calculating Sensitivity")
    print("="*70)

    all_metrics = {}
    for datacard_file, region_name in datacards:
        print(f"\n  Region: {region_name}")
        try:
            metrics = calculate_sensitivity_for_region(datacard_file)
            all_metrics[region_name] = metrics

            print(f"    Signal: {metrics['signal']:.4f} events")
            print(f"    Background: {metrics['total_background']:.4f} events")
            print(f"    S/B: {metrics['s_over_b']:.4f}")
            print(f"    Significance (Z): {metrics['significance']:.4f}")
        except Exception as e:
            print(f"    ✗ Error: {e}")

    # Summary table
    print("\n" + "="*70)
    print("Summary")
    print("="*70)

    if args.format == "table":
        print(f"\n{'Region':<20} {'Signal':>12} {'Background':>12} {'S/B':>10} {'Z':>10}")
        print("-" * 70)
        for region_name, metrics in sorted(all_metrics.items()):
            print(f"{region_name:<20} {metrics['signal']:>12.4f} "
                  f"{metrics['total_background']:>12.4f} "
                  f"{metrics['s_over_b']:>10.4f} "
                  f"{metrics['significance']:>10.4f}")

    elif args.format == "csv":
        print("Region,Signal,Background,S/B,Significance")
        for region_name, metrics in sorted(all_metrics.items()):
            print(f"{region_name},{metrics['signal']:.4f},"
                  f"{metrics['total_background']:.4f},"
                  f"{metrics['s_over_b']:.4f},"
                  f"{metrics['significance']:.4f}")

    print("\n" + "="*70)
    print("✓ Complete!")
    print("="*70)


if __name__ == "__main__":
    main()
